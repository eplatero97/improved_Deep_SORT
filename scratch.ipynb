{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch import nn\n",
    "\n",
    "class MetricNetwork(LightningModule):\n",
    "    def apply_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "    def __init__(self, single_embedding_shape: int):\n",
    "        super(MetricNetwork, self).__init__()\n",
    "        self.input_shape = single_embedding_shape*2 # the two input embeddings will be concatenated\n",
    "        ops = nn.ModuleList()\n",
    "        ops.append(nn.Linear(self.input_shape,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,2)) \n",
    "        ops.append(nn.Softmax()) # shape: [batch_size, 2] (after output)\n",
    "        self.net = nn.Sequential(*ops)\n",
    "        self.net.apply(self.apply_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: [batch_size, feats*2]\n",
    "        out = self.net(x) # shape: [batch_size, 2]\n",
    "        return out[:, 0] # shape: torch.Size([batch_size])\n",
    "\n",
    "\n",
    "class hold:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "model = MetricNetwork(128)\n",
    "h = hold(model)\n",
    "model.hello = \"hi\"\n",
    "h.model.hello # AttributeError: type object 'hold' has no attribute 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'hold' has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fb872bbe40dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'hold' has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "id(model), id(hold.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch import nn\n",
    "\n",
    "class MetricNetwork(LightningModule):\n",
    "    def apply_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "    def __init__(self, single_embedding_shape: int):\n",
    "        super(MetricNetwork, self).__init__()\n",
    "        self.input_shape = single_embedding_shape*2 # the two input embeddings will be concatenated\n",
    "        ops = nn.ModuleList()\n",
    "        ops.append(nn.Linear(self.input_shape,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,2)) \n",
    "        ops.append(nn.Softmax()) # shape: [batch_size, 2] (after output)\n",
    "        self.net = nn.Sequential(*ops)\n",
    "        self.net.apply(self.apply_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: [batch_size, feats*2]\n",
    "        out = self.net(x) # shape: [batch_size, 2]\n",
    "        return out[:, 0] # shape: torch.Size([batch_size])\n",
    "\n",
    "\n",
    "def add_property(model):\n",
    "    model.hello = \"hi\"\n",
    "\n",
    "model = MetricNetwork(128)\n",
    "add_property(model)\n",
    "model.hello # AttributeError: type object 'hold' has no attribute 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning.core.lightning import LightningModule\n",
    "from torch import nn\n",
    "\n",
    "class MetricNetwork(LightningModule):\n",
    "    def apply_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "    def __init__(self, single_embedding_shape: int):\n",
    "        super(MetricNetwork, self).__init__()\n",
    "        self.input_shape = single_embedding_shape*2 # the two input embeddings will be concatenated\n",
    "        ops = nn.ModuleList()\n",
    "        ops.append(nn.Linear(self.input_shape,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,10))\n",
    "        ops.append(nn.ReLU())\n",
    "        ops.append(nn.Linear(10,2)) \n",
    "        ops.append(nn.Softmax()) # shape: [batch_size, 2] (after output)\n",
    "        self.net = nn.Sequential(*ops)\n",
    "        self.net.apply(self.apply_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x.shape: [batch_size, feats*2]\n",
    "        out = self.net(x) # shape: [batch_size, 2]\n",
    "        return out[:, 0] # shape: torch.Size([batch_size])\n",
    "\n",
    "\n",
    "class hold:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self,model):\n",
    "        return model.hello\n",
    "\n",
    "\n",
    "model = MetricNetwork(128)\n",
    "model.hello = \"hi\"\n",
    "h = hold()\n",
    "h(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import ConcatDataset, TensorDataset, DataLoader\n",
    "import torch\n",
    "#from torch.utils.data.datasets import TensorDataset\n",
    "\n",
    "datasets = []\n",
    "for i in range(3):\n",
    "    datasets.append(TensorDataset(torch.arange(i*10, (i+1)*10)))\n",
    "\n",
    "dataset = ConcatDataset(datasets)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    batch_size=2\n",
    ")\n",
    "for data in loader:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cougarnet.uh.edu/eeplater/anaconda3/envs/deep_sort/lib/python3.6/site-packages/torchvision/transforms/transforms.py:1249: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms as T \n",
    "from siamese_net import *\n",
    "from pathlib import Path\n",
    "\n",
    "training_path=\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/Market-1501-v15.09.15/bounding_box_train_pt_format\"\n",
    "validation_path=\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/Market-1501-v15.09.15/gt_bbox_pt_format\"\n",
    "testing_path= list(Path(\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/MOT17/train\").rglob(\"crops_gt\"))\n",
    "training_batch_size=32\n",
    "validation_batch_size=32\n",
    "testing_batch_size=32\n",
    "transforms = T.Compose([\n",
    "\t\tT.Resize((128,64)),\n",
    "\t\tT.ColorJitter(hue=.05, saturation=.05),\n",
    "\t\tT.RandomHorizontalFlip(),\n",
    "\t\tT.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "\t\tT.ToTensor()\n",
    "\t\t# get_gaussian_mask()\n",
    "\t\t])\n",
    "criterion_name = \"triplet\"\n",
    "datamodule = DeepSORTModule(training_path=training_path, \n",
    "\t\t\t\t\t\t\t\t  validation_path=validation_path,\n",
    "\t\t\t\t\t\t\t\t  testing_path=testing_path,\n",
    "\t\t\t\t\t\t\t\t  training_batch_size=training_batch_size,\n",
    "\t\t\t\t\t\t\t\t  validation_batch_size=validation_batch_size,\n",
    "\t\t\t\t\t\t\t\t  testing_batch_size=testing_batch_size,\n",
    "\t\t\t\t\t\t\t\t  transforms=transforms,\n",
    "\t\t\t\t\t\t\t\t  mining=criterion_name)\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_path= list(Path(\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/MOT17/train\").rglob(\"crops_gt\"))\n",
    "if type(path) == str:\n",
    "    folder_dataset = dset.ImageFolder(root=path)\n",
    "elif type(path) == list:\n",
    "    folder_dataset = [dset.ImageFolder(root=root) for root in path]\n",
    "else:\n",
    "    print(f\"path is neither a string nor list: {type(path)}\")\n",
    "    raise \n",
    "\n",
    "\n",
    "if self.mining == \"triplet\":\n",
    "    if type(folder_dataset) == list:\n",
    "        siamese_dataset = ConcatDataset([SiameseTriplet(imageFolderDataset=fd,\n",
    "                                        transform=self.transforms,should_invert=False) for fd in folder_dataset])\n",
    "    siamese_dataset = SiameseTriplet(imageFolderDataset=folder_dataset,\n",
    "                                        transform=self.transforms,should_invert=False) # Get dataparser class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x7f7b2a6597f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_path= list(Path(\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/MOT17/train\").rglob(\"crops_gt\"))\n",
    "\n",
    "folder_dataset = [dset.ImageFolder(root=str(root)) for root in testing_path] # path MUST be string, NOT pathlib object\n",
    "\n",
    "siamese_dataset = ConcatDataset([SiameseTriplet(imageFolderDataset=fd,\n",
    "                                    transform=transforms,should_invert=False) for fd in folder_dataset])\n",
    "siamese_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [<siamese_dataloader.SiameseTriplet at 0x7f7b2a659828>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6978>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6a20>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce69e8>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce69b0>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6a90>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6ac8>],\n",
       " 'cumulative_sizes': [20202, 37652, 67655, 78272, 186277, 196688, 204701]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(siamese_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f7b2a6b1f28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(siamese_dataset)\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40fdc88e2a32def9c2d6259bee06fd52e38a0c8aa13e9d712f698015bd21f734"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 64-bit ('deep_sort': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
