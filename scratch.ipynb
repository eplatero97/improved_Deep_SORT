{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([ 0, 14])]\n",
      "[tensor([16,  2])]\n",
      "[tensor([3, 4])]\n",
      "[tensor([15,  5])]\n",
      "[tensor([25,  9])]\n",
      "[tensor([ 6, 29])]\n",
      "[tensor([11, 22])]\n",
      "[tensor([13, 18])]\n",
      "[tensor([ 8, 24])]\n",
      "[tensor([26, 28])]\n",
      "[tensor([21, 20])]\n",
      "[tensor([23, 17])]\n",
      "[tensor([ 1, 12])]\n",
      "[tensor([27, 19])]\n",
      "[tensor([10,  7])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import ConcatDataset, TensorDataset, DataLoader\n",
    "import torch\n",
    "#from torch.utils.data.datasets import TensorDataset\n",
    "\n",
    "datasets = []\n",
    "for i in range(3):\n",
    "    datasets.append(TensorDataset(torch.arange(i*10, (i+1)*10)))\n",
    "\n",
    "dataset = ConcatDataset(datasets)\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    batch_size=2\n",
    ")\n",
    "for data in loader:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cougarnet.uh.edu/eeplater/anaconda3/envs/deep_sort/lib/python3.6/site-packages/torchvision/transforms/transforms.py:1249: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n",
      "  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms as T \n",
    "from siamese_net import *\n",
    "from pathlib import Path\n",
    "\n",
    "training_path=\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/Market-1501-v15.09.15/bounding_box_train_pt_format\"\n",
    "validation_path=\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/Market-1501-v15.09.15/gt_bbox_pt_format\"\n",
    "testing_path= list(Path(\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/MOT17/train\").rglob(\"crops_gt\"))\n",
    "training_batch_size=32\n",
    "validation_batch_size=32\n",
    "testing_batch_size=32\n",
    "transforms = T.Compose([\n",
    "\t\tT.Resize((128,64)),\n",
    "\t\tT.ColorJitter(hue=.05, saturation=.05),\n",
    "\t\tT.RandomHorizontalFlip(),\n",
    "\t\tT.RandomRotation(20, resample=PIL.Image.BILINEAR),\n",
    "\t\tT.ToTensor()\n",
    "\t\t# get_gaussian_mask()\n",
    "\t\t])\n",
    "criterion_name = \"triplet\"\n",
    "datamodule = DeepSORTModule(training_path=training_path, \n",
    "\t\t\t\t\t\t\t\t  validation_path=validation_path,\n",
    "\t\t\t\t\t\t\t\t  testing_path=testing_path,\n",
    "\t\t\t\t\t\t\t\t  training_batch_size=training_batch_size,\n",
    "\t\t\t\t\t\t\t\t  validation_batch_size=validation_batch_size,\n",
    "\t\t\t\t\t\t\t\t  testing_batch_size=testing_batch_size,\n",
    "\t\t\t\t\t\t\t\t  transforms=transforms,\n",
    "\t\t\t\t\t\t\t\t  mining=criterion_name)\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_path= list(Path(\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/MOT17/train\").rglob(\"crops_gt\"))\n",
    "if type(path) == str:\n",
    "    folder_dataset = dset.ImageFolder(root=path)\n",
    "elif type(path) == list:\n",
    "    folder_dataset = [dset.ImageFolder(root=root) for root in path]\n",
    "else:\n",
    "    print(f\"path is neither a string nor list: {type(path)}\")\n",
    "    raise \n",
    "\n",
    "\n",
    "if self.mining == \"triplet\":\n",
    "    if type(folder_dataset) == list:\n",
    "        siamese_dataset = ConcatDataset([SiameseTriplet(imageFolderDataset=fd,\n",
    "                                        transform=self.transforms,should_invert=False) for fd in folder_dataset])\n",
    "    siamese_dataset = SiameseTriplet(imageFolderDataset=folder_dataset,\n",
    "                                        transform=self.transforms,should_invert=False) # Get dataparser class object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x7f7b2a6597f0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_path= list(Path(\"/home/cougarnet.uh.edu/eeplater/Documents/Datasets/MOT17/train\").rglob(\"crops_gt\"))\n",
    "\n",
    "folder_dataset = [dset.ImageFolder(root=str(root)) for root in testing_path] # path MUST be string, NOT pathlib object\n",
    "\n",
    "siamese_dataset = ConcatDataset([SiameseTriplet(imageFolderDataset=fd,\n",
    "                                    transform=transforms,should_invert=False) for fd in folder_dataset])\n",
    "siamese_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [<siamese_dataloader.SiameseTriplet at 0x7f7b2a659828>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6978>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6a20>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce69e8>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce69b0>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6a90>,\n",
       "  <siamese_dataloader.SiameseTriplet at 0x7f7b27ce6ac8>],\n",
       " 'cumulative_sizes': [20202, 37652, 67655, 78272, 186277, 196688, 204701]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(siamese_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f7b2a6b1f28>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(siamese_dataset)\n",
    "dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]]),\n",
       " tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dl))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40fdc88e2a32def9c2d6259bee06fd52e38a0c8aa13e9d712f698015bd21f734"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 64-bit ('deep_sort': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
